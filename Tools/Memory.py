from MCP_Tools import MCP_Tools
import mcp.types as types
import datetime
import os
import logging
import json
import asyncio
import math
import time
from dataclasses import dataclass
from typing import Dict, List, Optional, Annotated, Any
from pathlib import Path
import psycopg2
import psycopg2.extras
import threading
import hashlib

# –ü–æ–ø—ã—Ç–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ OpenAI (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
try:
    import openai
    HAS_OPENAI = True
except ImportError:
    HAS_OPENAI = False

# –ü–æ–ø—ã—Ç–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ numpy –¥–ª—è –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
try:
    import numpy as np
    HAS_NUMPY = True
except ImportError:
    HAS_NUMPY = False

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –¥–ª—è —Å–∏—Å—Ç–µ–º—ã –ø–∞–º—è—Ç–∏
MAX_DEPTH = 5
#SIMILARITY_THRESHOLD = 0.7
SIMILARITY_THRESHOLD = 0.2
DECAY_FACTOR = 0.99
REINFORCEMENT_FACTOR = 1.1
EMBEDDING_DIMENSION = 1536  # –î–ª—è text-embedding-3-small


@dataclass
class MemoryNode:
    """–£–∑–µ–ª –ø–∞–º—è—Ç–∏ —Å –≤–µ–∫—Ç–æ—Ä–Ω—ã–º –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ–º"""
    id: Optional[int] = None
    content: str = ""
    summary: str = ""
    importance: float = 1.0
    access_count: int = 0
    timestamp: Optional[datetime.datetime] = None
    embedding: Optional[List[float]] = None
    metadata: Optional[Dict[str, Any]] = None

    def __post_init__(self):
        if self.timestamp is None:
            self.timestamp = datetime.datetime.now(datetime.timezone.utc)
        if self.metadata is None:
            self.metadata = {}


class MemorySystem:
    """–°–∏—Å—Ç–µ–º–∞ —Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ–π –ø–∞–º—è—Ç–∏"""

    def __init__(self, db_url: str = None):
        self.db_url = db_url or os.environ.get("DATABASE_URL")
        if not self.db_url:
            raise ValueError("DATABASE_URL not found in environment variables")
        self.lock = threading.RLock()
        self.logger = logging.getLogger('MemorySystem')
        self._setup_database()

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ OpenAI –∫–ª–∏–µ–Ω—Ç–∞ –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
        self.openai_client = None
        if HAS_OPENAI:
            api_key = os.getenv("OPENAI_API_KEY")
            if api_key:
                self.openai_client = openai.OpenAI(api_key=api_key)
                self.logger.info("OpenAI client initialized")
            else:
                self.logger.warning("OPENAI_API_KEY not found in environment")

    def _setup_database(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö PostgreSQL"""
        try:
            with psycopg2.connect(self.db_url) as conn:
                with conn.cursor() as cursor:
                    cursor.execute("""
                        CREATE TABLE IF NOT EXISTS memories (
                            id SERIAL PRIMARY KEY,
                            content TEXT NOT NULL,
                            summary TEXT,
                            importance REAL DEFAULT 1.0,
                            access_count INTEGER DEFAULT 0,
                            timestamp TIMESTAMP WITH TIME ZONE NOT NULL,
                            embedding_json TEXT,
                            metadata_json TEXT,
                            content_hash TEXT UNIQUE
                        )
                    """)

                    cursor.execute("""
                        CREATE INDEX IF NOT EXISTS idx_importance ON memories(importance DESC)
                    """)

                    cursor.execute("""
                        CREATE INDEX IF NOT EXISTS idx_timestamp ON memories(timestamp DESC)
                    """)

                    cursor.execute("""
                        CREATE INDEX IF NOT EXISTS idx_content_hash ON memories(content_hash)
                    """)
                    
                    conn.commit()
                    self.logger.info("PostgreSQL database initialized successfully")
        except Exception as e:
            self.logger.error(f"Failed to initialize PostgreSQL database: {e}")
            raise

    def _get_embedding_sync(self, text: str) -> Optional[List[float]]:
        """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –ø–æ–ª—É—á–µ–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞"""
        if not self.openai_client:
            self.logger.warning(
                "OpenAI client not available, using simple hash-based embedding"
            )
            return self._simple_embedding(text)

        try:
            response = self.openai_client.embeddings.create(
                model="text-embedding-3-small", input=text)
            return response.data[0].embedding
        except Exception as e:
            self.logger.error(f"Failed to get OpenAI embedding: {e}")
            return self._simple_embedding(text)

    async def _get_embedding(self, text: str) -> Optional[List[float]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ OpenAI API"""
        if not self.openai_client:
            self.logger.warning(
                "OpenAI client not available, using simple hash-based embedding"
            )
            return self._simple_embedding(text)

        try:
            response = await asyncio.to_thread(
                self.openai_client.embeddings.create,
                model="text-embedding-3-small",
                input=text)
            return response.data[0].embedding
        except Exception as e:
            self.logger.error(f"Failed to get OpenAI embedding: {e}")
            return self._simple_embedding(text)

    def _simple_embedding(self, text: str) -> List[float]:
        """–ü—Ä–æ—Å—Ç–æ–µ —ç–º–±–µ–¥–¥–∏–Ω–≥ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ö–µ—à–∞ (fallback)"""
        # –°–æ–∑–¥–∞–µ–º –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤–µ–∫—Ç–æ—Ä –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ö–µ—à–∞ —Ç–µ–∫—Å—Ç–∞
        hash_obj = hashlib.md5(text.encode())
        hash_bytes = hash_obj.digest()

        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –≤–µ–∫—Ç–æ—Ä —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏
        embedding = []
        for i in range(min(EMBEDDING_DIMENSION, len(hash_bytes) * 8)):
            byte_idx = i // 8
            bit_idx = i % 8
            if byte_idx < len(hash_bytes):
                bit_val = (hash_bytes[byte_idx] >> bit_idx) & 1
                embedding.append(float(bit_val))
            else:
                embedding.append(0.0)

        # –î–æ–ø–æ–ª–Ω—è–µ–º –¥–æ –Ω—É–∂–Ω–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏
        while len(embedding) < EMBEDDING_DIMENSION:
            embedding.append(0.0)

        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º
        if HAS_NUMPY:
            embedding = np.array(embedding)
            norm = np.linalg.norm(embedding)
            if norm > 0:
                embedding = embedding / norm
            return embedding.tolist()
        else:
            # –ü—Ä–æ—Å—Ç–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –±–µ–∑ numpy
            norm = sum(x * x for x in embedding)**0.5
            if norm > 0:
                embedding = [x / norm for x in embedding]
            return embedding

    def _cosine_similarity(self, a: List[float], b: List[float]) -> float:
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –∫–æ—Å–∏–Ω—É—Å–Ω–æ–π —Å—Ö–æ–∂–µ—Å—Ç–∏ –º–µ–∂–¥—É –≤–µ–∫—Ç–æ—Ä–∞–º–∏"""
        if not HAS_NUMPY:
            # –ü—Ä–æ—Å—Ç–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –±–µ–∑ numpy
            dot_product = sum(x * y for x, y in zip(a, b))
            norm_a = sum(x * x for x in a)**0.5
            norm_b = sum(x * x for x in b)**0.5

            if norm_a == 0 or norm_b == 0:
                return 0.0

            return dot_product / (norm_a * norm_b)
        else:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º numpy –¥–ª—è –±–æ–ª–µ–µ —Ç–æ—á–Ω—ã—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
            a_array = np.array(a, dtype=np.float64)
            b_array = np.array(b, dtype=np.float64)
            return float(
                np.dot(a_array, b_array) /
                (np.linalg.norm(a_array) * np.linalg.norm(b_array)))

    def _content_hash(self, content: str) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ö–µ—à–∞ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤"""
        return hashlib.sha256(content.encode()).hexdigest()

    def add_memory_sync(self,
                        content: str,
                        importance: float = 1.0,
                        metadata: Optional[Dict[str, Any]] = None) -> int:
        """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏—è"""
        if not content.strip():
            raise ValueError("–°–æ–¥–µ—Ä–∂–∏–º–æ–µ –ø–∞–º—è—Ç–∏ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º")

        content_hash = self._content_hash(content)
        embedding = self._get_embedding_sync(content)

        if not embedding:
            raise RuntimeError("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ")

        # –°–æ–∑–¥–∞–Ω–∏–µ –∫—Ä–∞—Ç–∫–æ–≥–æ —Ä–µ–∑—é–º–µ (–ø–µ—Ä–≤—ã–µ 100 —Å–∏–º–≤–æ–ª–æ–≤)
        summary = content[:100] + "..." if len(content) > 100 else content

        memory_node = MemoryNode(content=content,
                                 summary=summary,
                                 importance=importance,
                                 embedding=embedding,
                                 metadata=metadata or {})

        with self.lock:
            try:
                with psycopg2.connect(self.db_url) as conn:
                    with conn.cursor() as cursor:
                        cursor.execute(
                            """
                            INSERT INTO memories (content, summary, importance, access_count, timestamp, embedding_json, metadata_json, content_hash)
                            VALUES (%s, %s, %s, %s, %s, %s, %s, %s) RETURNING id
                        """,
                            (memory_node.content, memory_node.summary,
                             memory_node.importance, memory_node.access_count,
                             memory_node.timestamp,
                             json.dumps(memory_node.embedding, ensure_ascii=False),
                             json.dumps(memory_node.metadata,
                                        ensure_ascii=False), content_hash))
                        memory_id = cursor.fetchone()[0]
                        conn.commit()

                self.logger.info(f"Memory added with ID: {memory_id}")
                return memory_id

            except psycopg2.IntegrityError:
                self.logger.warning(
                    f"Memory with this content already exists: {content[:50]}..."
                )
                # –í–æ–∑–≤—Ä–∞—â–∞–µ–º ID —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –∑–∞–ø–∏—Å–∏
                with psycopg2.connect(self.db_url) as conn:
                    with conn.cursor() as cursor:
                        cursor.execute(
                            "SELECT id FROM memories WHERE content_hash = %s",
                            (content_hash, ))
                        result = cursor.fetchone()
                        return result[0] if result else -1

    async def add_memory(self,
                         content: str,
                         importance: float = 1.0,
                         metadata: Optional[Dict[str, Any]] = None) -> int:
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤–æ–π –∑–∞–ø–∏—Å–∏ –≤ –ø–∞–º—è—Ç—å"""
        return await asyncio.to_thread(self.add_memory_sync, content,
                                       importance, metadata)

    def search_memories_sync(
            self,
            query: str,
            limit: int = 10,
            min_similarity: float = SIMILARITY_THRESHOLD
    ) -> List[Dict[str, Any]]:
        """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –ø–æ–∏—Å–∫–∞ –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π"""
        if not query.strip():
            return []

        query_embedding = self._get_embedding_sync(query)
        if not query_embedding:
            self.logger.error("Failed to create embedding for query")
            return []

        with self.lock:
            with psycopg2.connect(self.db_url) as conn:
                with conn.cursor() as cursor:
                    cursor.execute("""
                        SELECT id, content, summary, importance, access_count, timestamp, embedding_json, metadata_json
                        FROM memories 
                        ORDER BY importance DESC, timestamp DESC
                    """)

                    results = []
                    for row in cursor.fetchall():
                        memory_id, content, summary, importance, access_count, timestamp, embedding_json, metadata_json = row

                        try:
                            embedding = json.loads(
                                embedding_json) if embedding_json else []
                            metadata = json.loads(
                                metadata_json) if metadata_json else {}

                            if embedding:
                                similarity = self._cosine_similarity(
                                    query_embedding, embedding)

                                if similarity >= min_similarity:
                                    # –û–±–Ω–æ–≤–ª—è–µ–º —Å—á–µ—Ç—á–∏–∫ –¥–æ—Å—Ç—É–ø–∞ –∏ –≤–∞–∂–Ω–æ—Å—Ç—å
                                    new_access_count = access_count + 1
                                    new_importance = importance * REINFORCEMENT_FACTOR

                                    cursor.execute(
                                        """
                                        UPDATE memories 
                                        SET access_count = %s, importance = %s
                                        WHERE id = %s
                                    """, (new_access_count, new_importance,
                                          memory_id))

                                    results.append({
                                        'id': memory_id,
                                        'content': content,
                                        'summary': summary,
                                        'importance': new_importance,
                                        'access_count': new_access_count,
                                        'timestamp': timestamp.isoformat() if hasattr(timestamp, 'isoformat') else str(timestamp),
                                        'similarity': similarity,
                                        'metadata': metadata
                                    })
                        except (json.JSONDecodeError, Exception) as e:
                            self.logger.warning(
                                f"Error processing memory {memory_id}: {e}")
                            continue

                    conn.commit()
                    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Å—Ö–æ–∂–µ—Å—Ç–∏ –∏ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                    results.sort(key=lambda x: x['similarity'], reverse=True)
                    return results[:limit]

    async def search_memories(
            self,
            query: str,
            limit: int = 10,
            min_similarity: float = SIMILARITY_THRESHOLD
    ) -> List[Dict[str, Any]]:
        """–ü–æ–∏—Å–∫ –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π –ø–æ –∑–∞–ø—Ä–æ—Å—É"""
        return await asyncio.to_thread(self.search_memories_sync, query, limit,
                                       min_similarity)

    def get_all_memories_sync(self, limit: int = 100) -> List[Dict[str, Any]]:
        """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –ø–æ–ª—É—á–µ–Ω–∏—è –≤—Å–µ—Ö –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π"""
        with self.lock:
            with psycopg2.connect(self.db_url) as conn:
                with conn.cursor() as cursor:
                    cursor.execute(
                        """
                        SELECT id, content, summary, importance, access_count, timestamp, metadata_json
                        FROM memories 
                        ORDER BY importance DESC, timestamp DESC
                        LIMIT %s
                    """, (limit, ))

                    results = []
                    for row in cursor.fetchall():
                        memory_id, content, summary, importance, access_count, timestamp, metadata_json = row
                        try:
                            metadata = json.loads(
                                metadata_json) if metadata_json else {}
                            results.append({
                                'id': memory_id,
                                'content': content,
                                'summary': summary,
                                'importance': importance,
                                'access_count': access_count,
                                'timestamp': timestamp.isoformat() if hasattr(timestamp, 'isoformat') else str(timestamp),
                                'metadata': metadata
                            })
                        except json.JSONDecodeError:
                            results.append({
                                'id': memory_id,
                                'content': content,
                                'summary': summary,
                                'importance': importance,
                                'access_count': access_count,
                                'timestamp': timestamp.isoformat() if hasattr(timestamp, 'isoformat') else str(timestamp),
                                'metadata': {}
                            })

                    return results

    async def get_all_memories(self, limit: int = 100) -> List[Dict[str, Any]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π"""
        return await asyncio.to_thread(self.get_all_memories_sync, limit)

    def delete_memory_sync(self, memory_id: int) -> bool:
        """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è —É–¥–∞–ª–µ–Ω–∏—è –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏—è"""
        with self.lock:
            with psycopg2.connect(self.db_url) as conn:
                with conn.cursor() as cursor:
                    cursor.execute("DELETE FROM memories WHERE id = %s",
                                          (memory_id, ))
                    deleted = cursor.rowcount > 0
                    conn.commit()

                    if deleted:
                        self.logger.info(f"Memory {memory_id} deleted")
                    else:
                        self.logger.warning(
                            f"Memory {memory_id} not found for deletion")

                    return deleted

    async def delete_memory(self, memory_id: int) -> bool:
        """–£–¥–∞–ª–µ–Ω–∏–µ –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏—è –ø–æ ID"""
        return await asyncio.to_thread(self.delete_memory_sync, memory_id)

    def cleanup_old_memories_sync(self,
                                  max_age_days: int = 30,
                                  max_count: int = 1000) -> int:
        """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –æ—á–∏—Å—Ç–∫–∏ —Å—Ç–∞—Ä—ã—Ö –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π"""
        cutoff_date = datetime.datetime.now(
            datetime.timezone.utc) - datetime.timedelta(days=max_age_days)

        with self.lock:
            with psycopg2.connect(self.db_url) as conn:
                with conn.cursor() as cursor:
                    # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–∏–º–µ–Ω—è–µ–º decay –∫ —Å—Ç–∞—Ä—ã–º –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏—è–º
                    cursor.execute(
                        """
                        UPDATE memories 
                        SET importance = importance * %s
                        WHERE timestamp < %s
                    """, (DECAY_FACTOR, cutoff_date))

                    # –£–¥–∞–ª—è–µ–º —Å–∞–º—ã–µ –Ω–µ–≤–∞–∂–Ω—ã–µ –∑–∞–ø–∏—Å–∏, –µ—Å–ª–∏ –∏—Ö —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ
                    cursor.execute("SELECT COUNT(*) FROM memories")
                    total_count = cursor.fetchone()[0]

                    deleted_count = 0
                    if total_count > max_count:
                        delete_count = total_count - max_count
                        cursor.execute(
                            """
                            DELETE FROM memories 
                            WHERE id IN (
                                SELECT id FROM memories 
                                ORDER BY importance ASC, access_count ASC 
                                LIMIT %s
                            )
                        """, (delete_count, ))
                        deleted_count = cursor.rowcount
                        
                    conn.commit()
                    self.logger.info(f"Cleaned up {deleted_count} old memories")
                    return deleted_count

    async def cleanup_old_memories(self,
                                   max_age_days: int = 30,
                                   max_count: int = 1000) -> int:
        """–û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –∏ –Ω–µ–≤–∞–∂–Ω—ã—Ö –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π"""
        return await asyncio.to_thread(self.cleanup_old_memories_sync,
                                       max_age_days, max_count)


class MemoryTools:
    """–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –ø–∞–º—è—Ç—å—é –≤ MCP"""

    def __init__(self, mcp: MCP_Tools) -> None:
        self.tz_plus3 = datetime.timezone(datetime.timedelta(hours=3))
        self.memory_system = MemorySystem()
        self.logger = logging.getLogger('MemoryTools')

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        if not self.logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s')
            handler.setFormatter(formatter)
            self.logger.addHandler(handler)
            self.logger.setLevel(logging.INFO)

        self._register_tools(mcp)
        self.logger.info("MemoryTools initialized")

    def _safe_run_async(self, coro):
        """–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –∑–∞–ø—É—Å–∫ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ –∫–æ–¥–∞ –≤ MCP –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –∞–∫—Ç–∏–≤–Ω—ã–π event loop
            loop = asyncio.get_running_loop()
            # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á—É –≤ —Ç–µ–∫—É—â–µ–º loop
            future = asyncio.ensure_future(coro, loop=loop)
            # –ñ–¥–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Å —Ç–∞–π–º–∞—É—Ç–æ–º
            timeout = 30  # 30 —Å–µ–∫—É–Ω–¥ —Ç–∞–π–º–∞—É—Ç
            start_time = time.time()
            while not future.done() and (time.time() - start_time) < timeout:
                time.sleep(0.01)

            if future.done():
                return future.result()
            else:
                future.cancel()
                raise TimeoutError("Async operation timed out")

        except RuntimeError:
            # –ï—Å–ª–∏ –Ω–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ–≥–æ loop, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–µ –≤–µ—Ä—Å–∏–∏
            self.logger.info("No active event loop, using sync versions")
            return None
        except Exception as e:
            self.logger.error(f"Error in async execution: {e}")
            raise

    def _register_tools(self, mcp: MCP_Tools):
        """–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –≤—Å–µ—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –ø–∞–º—è—Ç–∏"""

        @mcp.register_tool(name="add_memory",
                           description="–î–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤–æ–µ –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–µ –≤ –ø–∞–º—è—Ç—å")
        def add_memory(
            content: Annotated[str, "–°–æ–¥–µ—Ä–∂–∏–º–æ–µ –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏—è"],
            importance: Annotated[float,
                                  "–í–∞–∂–Ω–æ—Å—Ç—å –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏—è (0.0-10.0)"] = 1.0,
            tags: Annotated[str, "–¢–µ–≥–∏ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)"] = ""
        ) -> list[types.TextContent | types.ImageContent
                  | types.EmbeddedResource]:
            try:
                if not content.strip():
                    return [
                        types.TextContent(
                            type="text",
                            text="–û—à–∏–±–∫–∞: –°–æ–¥–µ—Ä–∂–∏–º–æ–µ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º")
                    ]

                # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
                metadata = {}
                if tags.strip():
                    metadata['tags'] = [
                        tag.strip() for tag in tags.split(',') if tag.strip()
                    ]
                metadata['created_at'] = datetime.datetime.now(
                    self.tz_plus3).isoformat()

                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é
                memory_id = self.memory_system.add_memory_sync(
                    content, importance, metadata)

                if memory_id > 0:
                    self.logger.info(f"Added memory with ID: {memory_id}")
                    return [
                        types.TextContent(
                            type="text",
                            text=
                            f"‚úÖ –í–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–µ –¥–æ–±–∞–≤–ª–µ–Ω–æ –≤ –ø–∞–º—è—Ç—å —Å ID: {memory_id}"
                        )
                    ]
                else:
                    return [
                        types.TextContent(
                            type="text",
                            text=
                            "‚ö†Ô∏è –í–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–µ —Å —Ç–∞–∫–∏–º —Å–æ–¥–µ—Ä–∂–∏–º—ã–º —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç"
                        )
                    ]

            except Exception as e:
                error_msg = f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏—è: {str(e)}"
                self.logger.error(error_msg)
                return [types.TextContent(type="text", text=error_msg)]

        @mcp.register_tool(name="search_memory",
                           description="–ü–æ–∏—Å–∫ –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π –ø–æ –∑–∞–ø—Ä–æ—Å—É")
        def search_memory(
            query: Annotated[str, "–ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å"],
            limit: Annotated[int, "–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"] = 10,
            min_similarity: Annotated[
                float, "–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Å—Ö–æ–∂–µ—Å—Ç—å (0.0-1.0)"] = SIMILARITY_THRESHOLD
        ) -> list[types.TextContent | types.ImageContent
                  | types.EmbeddedResource]:
            try:
                if not query.strip():
                    return [
                        types.TextContent(
                            type="text",
                            text="–û—à–∏–±–∫–∞: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º"
                        )
                    ]

                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é
                results = self.memory_system.search_memories_sync(
                    query, limit, min_similarity)

                if not results:
                    return [
                        types.TextContent(
                            type="text",
                            text=
                            f"üîç –ü–æ –∑–∞–ø—Ä–æ—Å—É '{query}' –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                    ]

                # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –Ω–∞ None
                response = f"üîç –ù–∞–π–¥–µ–Ω–æ {len(results)} –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π –ø–æ –∑–∞–ø—Ä–æ—Å—É '{query}':\n\n"

                for i, memory in enumerate(results, 1):
                    try:
                        timestamp = datetime.datetime.fromisoformat(
                            memory['timestamp']).strftime("%Y-%m-%d %H:%M")
                    except:
                        timestamp = "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"

                    similarity_percent = (memory.get('similarity', 0)
                                          or 0) * 100
                    importance = memory.get('importance', 0) or 0

                    response += f"**{i}. [ID: {memory.get('id', 'unknown')}]** (—Å—Ö–æ–∂–µ—Å—Ç—å: {similarity_percent:.1f}%)\n"
                    response += f"üìÖ {timestamp} | üî• –í–∞–∂–Ω–æ—Å—Ç—å: {importance:.2f}\n"
                    response += f"üìù {memory.get('summary', '–ë–µ–∑ –æ–ø–∏—Å–∞–Ω–∏—è')}\n"

                    content = memory.get('content', '')
                    if len(content) > 200:
                        response += f"üí≠ {content[:200]}...\n"
                    else:
                        response += f"üí≠ {content}\n"

                    if memory.get('metadata',
                                  {}) and memory['metadata'].get('tags'):
                        tags = ', '.join(memory['metadata']['tags'])
                        response += f"üè∑Ô∏è –¢–µ–≥–∏: {tags}\n"

                    response += "\n"

                self.logger.info(
                    f"Search completed: {len(results)} results for '{query}'")
                return [types.TextContent(type="text", text=response)]

            except Exception as e:
                error_msg = f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π: {str(e)}"
                self.logger.error(error_msg)
                return [types.TextContent(type="text", text=error_msg)]

        @mcp.register_tool(name="list_memories",
                           description="–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π")
        def list_memories(
            limit: Annotated[int, "–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π"] = 20
        ) -> list[types.TextContent | types.ImageContent
                  | types.EmbeddedResource]:
            try:
                memories = self.memory_system.get_all_memories_sync(limit)

                if not memories:
                    return [
                        types.TextContent(
                            type="text",
                            text="üìù –ü–∞–º—è—Ç—å –ø—É—Å—Ç–∞ - –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                    ]

                response = f"üìö –ü–æ—Å–ª–µ–¥–Ω–∏–µ {len(memories)} –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π:\n\n"

                for i, memory in enumerate(memories, 1):
                    try:
                        timestamp = datetime.datetime.fromisoformat(
                            memory['timestamp']).strftime("%Y-%m-%d %H:%M")
                    except:
                        timestamp = "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"

                    importance = memory.get('importance', 0) or 0
                    access_count = memory.get('access_count', 0) or 0

                    response += f"**{i}. [ID: {memory.get('id', 'unknown')}]**\n"
                    response += f"üìÖ {timestamp} | üî• –í–∞–∂–Ω–æ—Å—Ç—å: {importance:.2f} | üëÅÔ∏è –ü—Ä–æ—Å–º–æ—Ç—Ä—ã: {access_count}\n"
                    response += f"üìù {memory.get('summary', '–ë–µ–∑ –æ–ø–∏—Å–∞–Ω–∏—è')}\n"

                    if memory.get('metadata',
                                  {}) and memory['metadata'].get('tags'):
                        tags = ', '.join(memory['metadata']['tags'])
                        response += f"üè∑Ô∏è –¢–µ–≥–∏: {tags}\n"

                    response += "\n"

                self.logger.info(f"Listed {len(memories)} memories")
                return [types.TextContent(type="text", text=response)]

            except Exception as e:
                error_msg = f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–ø–∏—Å–∫–∞ –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π: {str(e)}"
                self.logger.error(error_msg)
                return [types.TextContent(type="text", text=error_msg)]

        @mcp.register_tool(name="delete_memory",
                           description="–£–¥–∞–ª–∏—Ç—å –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–µ –ø–æ ID")
        def delete_memory(
            memory_id: Annotated[int, "ID –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏—è –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è"]
        ) -> list[types.TextContent | types.ImageContent
                  | types.EmbeddedResource]:
            try:
                success = self.memory_system.delete_memory_sync(memory_id)

                if success:
                    self.logger.info(f"Deleted memory with ID: {memory_id}")
                    return [
                        types.TextContent(
                            type="text",
                            text=
                            f"‚úÖ –í–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–µ —Å ID {memory_id} —É—Å–ø–µ—à–Ω–æ —É–¥–∞–ª–µ–Ω–æ")
                    ]
                else:
                    return [
                        types.TextContent(
                            type="text",
                            text=f"‚ùå –í–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–µ —Å ID {memory_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
                    ]

            except Exception as e:
                error_msg = f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏—è: {str(e)}"
                self.logger.error(error_msg)
                return [types.TextContent(type="text", text=error_msg)]

        @mcp.register_tool(
            name="cleanup_memory",
            description="–û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –∏ –Ω–µ–≤–∞–∂–Ω—ã—Ö –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π")
        def cleanup_memory(
            max_age_days: Annotated[
                int, "–ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –≤–æ–∑—Ä–∞—Å—Ç –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π –≤ –¥–Ω—è—Ö"] = 30,
            max_count: Annotated[int,
                                 "–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π"] = 1000
        ) -> list[types.TextContent | types.ImageContent
                  | types.EmbeddedResource]:
            try:
                deleted_count = self.memory_system.cleanup_old_memories_sync(
                    max_age_days, max_count)

                self.logger.info(
                    f"Memory cleanup completed: {deleted_count} memories deleted"
                )
                return [
                    types.TextContent(
                        type="text",
                        text=
                        f"üßπ –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –£–¥–∞–ª–µ–Ω–æ {deleted_count} —Å—Ç–∞—Ä—ã—Ö –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π"
                    )
                ]

            except Exception as e:
                error_msg = f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ –ø–∞–º—è—Ç–∏: {str(e)}"
                self.logger.error(error_msg)
                return [types.TextContent(type="text", text=error_msg)]

        @mcp.register_tool(name="memory_stats",
                           description="–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Å–∏—Å—Ç–µ–º—ã –ø–∞–º—è—Ç–∏")
        def memory_stats() -> list[types.TextContent | types.ImageContent
                                   | types.EmbeddedResource]:
            try:
                with psycopg2.connect(self.memory_system.db_url) as conn:
                    with conn.cursor() as cursor:
                        # –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π
                        cursor.execute("SELECT COUNT(*) FROM memories")
                        total_memories = cursor.fetchone()[0]

                        # –¢–æ–ø-5 –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏
                        cursor.execute("""
                            SELECT content, importance, access_count 
                            FROM memories 
                            ORDER BY importance DESC 
                            LIMIT 5
                        """)
                        top_memories = cursor.fetchall()

                        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –≤–æ–∑—Ä–∞—Å—Ç—É —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –Ω–∞ None
                        cursor.execute("""
                            SELECT 
                                COUNT(*) as count,
                                AVG(importance) as avg_importance,
                                AVG(access_count) as avg_access
                            FROM memories 
                            WHERE timestamp > NOW() - INTERVAL '7 days'
                        """)
                        recent_stats = cursor.fetchone()

                has_openai = "‚úÖ" if getattr(self.memory_system,
                                            'openai_client', None) else "‚ùå"
                has_numpy = "‚úÖ" if HAS_NUMPY else "‚ùå"

                response = "üìä **–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–∏—Å—Ç–µ–º—ã –ø–∞–º—è—Ç–∏:**\n\n"
                response += f"üß† –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π: **{total_memories or 0}**\n"
                response += f"üìà –í–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏—è –∑–∞ –ø–æ—Å–ª–µ–¥–Ω—é—é –Ω–µ–¥–µ–ª—é: **{recent_stats[0] or 0}**\n"

                # –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –Ω–∞ None
                avg_importance = recent_stats[1] if recent_stats[
                    1] is not None else 0
                avg_access = recent_stats[2] if recent_stats[
                    2] is not None else 0

                response += f"‚ö° –°—Ä–µ–¥–Ω—è—è –≤–∞–∂–Ω–æ—Å—Ç—å (–Ω–µ–¥–µ–ª—è): **{avg_importance:.2f}**\n"
                response += f"üëÅÔ∏è –°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤ (–Ω–µ–¥–µ–ª—è): **{avg_access:.1f}**\n\n"

                response += "üîß **–°–æ—Å—Ç–æ—è–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã:**\n"
                response += f"OpenAI API: {has_openai}\n"
                response += f"NumPy: {has_numpy}\n"
                response += f"–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö: PostgreSQL\n\n"

                if top_memories:
                    response += "üî• **–¢–æ–ø-5 –≤–∞–∂–Ω—ã—Ö –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π:**\n"
                    for i, (content, importance,
                            access_count) in enumerate(top_memories, 1):
                        content = content or "–ü—É—Å—Ç–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ"
                        importance = importance or 0
                        access_count = access_count or 0
                        preview = content[:60] + "..." if len(
                            content) > 60 else content
                        response += f"{i}. {preview} (–≤–∞–∂–Ω–æ—Å—Ç—å: {importance:.2f}, –ø—Ä–æ—Å–º–æ—Ç—Ä—ã: {access_count})\n"

                return [types.TextContent(type="text", text=response)]

            except Exception as e:
                error_msg = f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {str(e)}"
                self.logger.error(error_msg)
                return [types.TextContent(type="text", text=error_msg)]
